{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNhLuOXqpHpW6kYWw8TlMR3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dsj3EniGrOzk"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pylab as plt\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential,Model\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","#MNIST 데이터셋을 로드하여 준비. 샘플 값을 정수에서 부동소수로 변환\n","(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","# 28x28차원의 벡터가 60000개 채널은 1개\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","\n","from tensorflow.keras.utils import to_categorical\n","\n","one_hot_train_labels = to_categorical(train_labels, 10)\n","one_hot_test_labels = to_categorical(test_labels, 10)\n","print(one_hot_train_labels[:10])\n","\n","\n","# Functional API를 이용한 모델 구현\n","# tensorflow.keras.models.Model의 inputs() & outputs() 메소드 설정을 이용해 모델 정의x`\n","# (1) Convolution layer\n","\n","inputs = tf.keras.Input(shape=(28*28, ))\n","x=Dense(input_dim=784,units=256,activation='relu')(inputs)\n","y=Dense(input_dim=784,units=256,activation='relu')(inputs)\n","C=x+y\n","outputs=Dense(input_dim=256,units=10,activation='sigmoid') (C)\n","model=Model(inputs=inputs,outputs=outputs)\n","\n","# 모델 학습과정 설정\n","model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 구조 요약 출력\n","model.summary()\n","\n","# 모델 학습\n","history = model.fit(train_images, one_hot_train_labels, epochs=5, batch_size=10)\n","\n","print(\"\\n=============test results==========\")\n","labels=model.predict(test_images)\n","print(\"\\n Accuracy: %.4f\" % (model.evaluate(test_images, one_hot_test_labels, verbose=2)[1\n","])) #list index"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pylab as plt\n","from tensorflow.keras.models import Sequential,Model\n","from tensorflow.keras.layers import Dense, Input, Dropout\n","from tensorflow.keras.datasets import mnist\n","\n","n_output = 784\n","n_noise = 128\n","\n","generator = Sequential()\n","generator.add(Dense(units=256, input_dim=n_noise, activation='relu'))\n","generator.add(Dense(units=512, activation='relu'))\n","generator.add(Dense(units=n_output, activation='tanh'))\n","\n","discriminator = Sequential()\n","discriminator.add(Dense(256, input_dim=n_output, activation='relu'))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(1, activation='sigmoid'))\n","\n","g_input = Input(shape=(n_noise,))\n","g_output = discriminator(generator(g_input))\n","gan = Model(g_input, g_output)\n","\n","discriminator.trainable = True\n","adam = tf.optimizers.legacy.Adam(lr=0.0002, beta_1=0.5)\n","discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n","\n","discriminator.trainable = False\n","gan.compile(loss='binary_crossentropy', optimizer=adam)\n","\n","gan.summary()\n","\n","n_epoch = 100\n","batch_size = 128\n","saving_interval = 10\n","\n","(train_images, _), (_, _) = mnist.load_data()\n","\n","buffer_size = len(train_images)\n","train_images = train_images.reshape((buffer_size, n_output))\n","\n","train_images = (train_images - 127.5) / 127.5\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n","\n","for i in  range(n_epoch):\n","  print('Epoch Num : {}/{}'.format((i + 1), n_epoch))\n","\n","  for image_batch in train_dataset:\n","    n_bt_imgs = len(image_batch)\n","    true_labels = np.ones((n_bt_imgs, 1))\n","    fake_labels = np.ones((n_bt_imgs, 1))\n","\n","    d_loss_real=discriminator.train_on_batch(image_batch,true_labels)\n","\n","    noise = np.random.normal(0, 1, (n_bt_imgs, n_noise))\n","    gen_imgs = generator.predict(noise)\n","    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake_labels)\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","    g_loss = gan.train_on_batch(noise, true_labels)\n","\n","    if (i + 1) % saving_interval == 0 or i == 1:\n","      print('Epoch:%d' % (i + 1),\n","            'd_loss:%.4f' % d_loss, 'g_loss:%.4f' % g_loss)\n","\n","      noise = np.random.normal(0, 1, (25, n_noise))\n","      gen_imgs = generator.predict(noise)\n","\n","      gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","      fig, axs = plt.subplots(5, 5)\n","      count = 0\n","      for j in range(5):\n","        for k in range(5):\n","          axs[j, k].imshow(np.reshape(gen_imgs[count], (28, 28)))\n","          axs[j, k].axis('off')\n","          count += 1\n","      plt.show()\n"],"metadata":{"id":"VaVOwq4YrGz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout\n","from tensorflow.keras.models import Sequential, Model\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","n_output = 784   # 28×28 이미지 크기\n","n_noise = 128    # 랜덤 노이즈 벡터 크기\n","\n","# 생성자 모델 정의\n","# 128차원의 랜덤 노이즈 벡터를 입력받아서 784차원의 벡터(28×28)이미지를 출력\n","generator = Sequential()\n","generator.add(Dense(units=256 , input_dim=n_noise))\n","generator.add(LeakyReLU(0.2))\n","generator.add(Dense(units=512 ))\n","generator.add(LeakyReLU(0.2))\n","generator.add(Dense(units=1024))\n","generator.add(LeakyReLU(0.2))\n","generator.add(Dense(units=n_output, activation='tanh'))\n","\n","# 판별자 모델 정의\n","discriminator = Sequential()\n","discriminator.add(Dense(1024, input_dim=n_output))\n","discriminator.add(LeakyReLU(0.2))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(512))\n","discriminator.add(LeakyReLU(0.2))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(256))\n","discriminator.add(LeakyReLU(0.2))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(1, activation='sigmoid'))\n","\n","# 생성자와 판별자 모델을 통합한 GAN 모델 구현\n","g_input = Input(shape=(n_noise,))\n","g_output = discriminator(generator(g_input))\n","gan = Model(g_input, g_output)\n","\n","# 판별자 모델 학습을 위한 최적화 함수 및 손실 함수 설정\n","discriminator.trainable = True\n","adam = tf.optimizers.legacy.Adam(learning_rate=0.0002, beta_1=0.5)\n","discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n","\n","\n","# GAN 모델 학습을 위한 최적화 함수 및 손실 함수 설정\n","# GAN 모델에 대한 학습은 오직 생성자에 대한 가중치 업데이트가 수행되어야 하므로 판별자 모델의 학습 여부를 False로 설정함\n","discriminator.trainable = False\n","gan.compile(loss='binary_crossentropy', optimizer=adam)\n","\n","# GAN 모델 구조 출력\n","gan.summary()\n","\n","# 모델 학습\n","n_epoch = 100\n","batch_size = 128\n","saving_interval = 10\n","\n","# MNIST 데이터 불러오기\n","# 모델 학습을 위해서는 훈련 이미지만 사용할 것이기 때문에 train_images만 로드\n","(train_images, _), (_, _) = mnist.load_data()\n","\n","buffer_size = len(train_images)  # 60000\n","train_images = train_images.reshape((buffer_size, n_output)) #28x28\n","\n","# 이미지 픽셀값을 [–1~1]로 정규화\n","train_images = (train_images - 127.5) / 127.5\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n","\n","for i in range(n_epoch):\n","    print('Epoch Num : {}/{}'.format((i + 1), n_epoch))\n","\n","    # 1) 미니-배치별 모델 가중치 갱신 및 오차 계산\n","    for image_batch in train_dataset:    # 미니-배치별 가중치 갱신\n","        # 현재 배치 크기만큼 진짜 및 가짜 레이블 배열 생성\n","        n_bt_imgs = len(image_batch)\n","        true_labels = np.ones((n_bt_imgs, 1))  # 진짜 레이블(1) 생성\n","        fake_labels = np.zeros((n_bt_imgs, 1)) # 가짜 레이블(0) 생성\n","\n","        # 현재 배치에 대한 판별자 모델의 가중치 1회 갱신 및 오차 갱신\n","        # 진짜 이미지에 대한 판별자 모델 가중치 갱신 및 오차 계산\n","        d_loss_real = discriminator.train_on_batch(image_batch, true_labels)\n","        # 가짜 이미지에 대한 판별자 모델 가중치 갱신 및 오차 계산\n","        noise = np.random.normal(0, 1, (n_bt_imgs, n_noise))\n","        gen_imgs = generator.predict(noise)\n","        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake_labels)\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","        # 현재 배치에 대한 GAN 모델 가중치 1회 갱신 및 오차 계산\n","        g_loss = gan.train_on_batch(noise, true_labels)\n","\n","    # 2) 중간 과정 생성되는 이미지 확인\n","    if (i +1) % saving_interval == 0 or i == 1:\n","        print('Epoch:%d' % (i + 1),\n","             'd_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n","\n","        # 학습된 생성자 모델을 이용하여 25개의 이미지 생성\n","        noise = np.random.normal(0, 1, (25, n_noise))  # 25개의 노이즈 벡터 생성\n","        gen_imgs = generator.predict(noise)  # 생성자를 이용한 25개의 이미지 생성\n","\n","        # 이미지 픽셀값 0~1로 조정\n","        #gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","       # 생성된 이미지 출력 및 저장\n","        fig, axs = plt.subplots(5, 5)\n","        count = 0\n","        for j in range(5):\n","            for k in range(5):\n","                axs[j, k].imshow(np.reshape(gen_imgs[count], (28, 28)))\n","                axs[j, k].axis('off')\n","                count += 1\n","        plt.show()\n","        #fig.savefig(\"gan_results/g_mnist_%d.png\" % (i + 1))"],"metadata":{"id":"9P4bMu1aj9Le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcQlmC9Vn25u","executionInfo":{"status":"ok","timestamp":1702260558081,"user_tz":-540,"elapsed":20406,"user":{"displayName":"서상훈","userId":"08223198468266376619"}},"outputId":"875e9062-8c4b-4a52-974e-d06a9b002f5c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# Style Transfer\n","\n","\n","import tensorflow as tf\n","from PIL import Image #이미지 분석 및 처리 Pillow 라이브러리\n","import numpy as np\n","import matplotlib.pyplot as plt\n","#TensorFlow Hub는 재사용 가능한 머신러닝을 위한 개방형 리포지토리 및 라이브러리\n","import tensorflow_hub as hub\n","import functools\n","import os\n","\n","#load image\n","def load_image(image_path):\n","  image = tf.io.read_file(image_path)\n","  image = tf.image.decode_image(image, channels=3)\n","  image = tf.image.convert_image_dtype(image, tf.float32)\n","  image = tf.image.resize(image, (256,256))\n","  #tr.newaxis를 이용한 reshape방법. 맨 앞에 shape 1이 추가 (원래 image(256,256,3))=>(1,256,256,3)\n","  image = image[tf.newaxis,:]\n","  #print(image)\n","  return image\n","\n","def tensor2image(image):\n","  image = image*255.0\n","  image = np.array(image, dtype=np.uint8)\n","  return Image.fromarray(image)\n","\n","content_image = load_image('/content/gdrive/My Drive/content1.png')\n","style_image = load_image('/content/gdrive/My Drive/style1.jpg')\n","\n","hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n","stylized_image = hub_module(tf.constant(content_image), tf.constant(style_image))[0][0]\n","#stylized_image = outputs[0][0]\n","\n","final_image = tensor2image(stylized_image)\n","if final_image.mode != 'RGB':\n","    final_image = final_image.convert('RGB')\n","final_image.save('/content/gdrive/My Drive/stylized_image1.jpg')"],"metadata":{"id":"q5M1jljSnwrI","executionInfo":{"status":"ok","timestamp":1702260782699,"user_tz":-540,"elapsed":4795,"user":{"displayName":"서상훈","userId":"08223198468266376619"}}},"execution_count":7,"outputs":[]}]}